{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create some data that isn't plates so that the CNN recognice if it's either catputing plates or not, and what exactly counts as a plate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import urllib\n",
    "from PIL import Image\n",
    "url='Indian_Number_plates.json'\n",
    "data = pd.read_json('Indian_Number_plates.json', lines=True)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "# Se borra la columna extra \n",
    "del data['extras']\n",
    "\n",
    "# Se extraen los puntos con las cajas de la placa\n",
    "data['points'] = data.apply(lambda row: row['annotation'][0]['points'], axis=1)\n",
    "\n",
    "#se borra el resto de los datos\n",
    "del data['annotation']\n",
    "data.head()\n",
    "\n",
    "\n",
    "IMG_SIZE=128\n",
    "\n",
    "\n",
    "Images = []\n",
    "training_data=[]\n",
    "\n",
    "def imagesplitter(row,im,split,label):\n",
    "        # Points of rectangle\n",
    "        if label==0:\n",
    "            \n",
    "            x_point_top = row[1][0]['x']*im.shape[1]/split\n",
    "            y_point_top = row[1][0]['y']*im.shape[0]/split\n",
    "            x_point_bot = row[1][1]['x']*im.shape[1]/split\n",
    "            y_point_bot = row[1][1]['y']*im.shape[0]/split\n",
    "\n",
    "            # Cut the plate from the image and use it as output\n",
    "            carImage = Image.fromarray(im)\n",
    "            plateImage = carImage.crop((x_point_top, y_point_top, x_point_bot, y_point_bot))\n",
    "        else:\n",
    "            plateImage  = Image.fromarray(im)\n",
    "        new_plateImage=plateImage.resize((IMG_SIZE,IMG_SIZE))\n",
    "        training_data.append([new_plateImage, label])  # add this to our training_data\n",
    "        \n",
    "    \n",
    "def downloadTraining(df):\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "\n",
    "        # Get the image from the URL\n",
    "        resp = urllib.request.urlopen(row[0])\n",
    "        im = np.array(Image.open(resp))\n",
    "        # We append the image to the training input array\n",
    "        Images.append(im)  \n",
    "        imagesplitter(row,im,1,0) #add plate\n",
    "        imagesplitter(row,im,2,1) #add somthing that isnt a plate\n",
    "\n",
    "downloadTraining(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see some data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Create figure and axes\n",
    "fig, ax = plt.subplots(2, 1, constrained_layout=True)\n",
    "\n",
    "# Set title\n",
    "ax[0].set_title('Input Image')\n",
    "ax[1].set_title('Output Image')\n",
    "\n",
    "# Display the images\n",
    "ax[0].imshow(Images[0])\n",
    "ax[1].imshow(training_data[0][0])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "474"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is the amount of data we have\n",
    "len(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pass this to a format that would be received to our model conv layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image input error, do not add to the format output\n",
      "Image input error, do not add to the format output\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pickle\n",
    "random.shuffle(training_data)\n",
    "Features_output = []\n",
    "Labels_output = []\n",
    "for features,label in training_data:\n",
    "    try:\n",
    "        opencvImage = cv2.cvtColor(np.array(features), cv2.COLOR_RGB2BGR)    \n",
    "        Features_output.append(opencvImage)\n",
    "        Labels_output.append(label)\n",
    "    except:\n",
    "        print(\"Image input error, do not add to the format output\") \n",
    "\n",
    "\n",
    "\n",
    "Features_output = np.array(Features_output).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "#we proceed to save the output \n",
    "\n",
    "pickle_out = open(\"Features_output.pickle\",\"wb\")\n",
    "pickle.dump(Features_output, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"Labels_output.pickle\",\"wb\")\n",
    "pickle.dump(Labels_output, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start with some training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0820 21:53:36.723319 140593079056192 deprecation.py:506] From /home/alejandro/miniconda3/envs/py3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0820 21:53:37.128832 140593079056192 deprecation.py:323] From /home/alejandro/miniconda3/envs/py3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 330 samples, validate on 142 samples\n",
      "Epoch 1/10\n",
      "330/330 [==============================] - 44s 132ms/sample - loss: 2.6253 - acc: 0.4879 - val_loss: 0.6888 - val_acc: 0.5775\n",
      "Epoch 2/10\n",
      "330/330 [==============================] - 36s 108ms/sample - loss: 0.6156 - acc: 0.6939 - val_loss: 0.5093 - val_acc: 0.7676\n",
      "Epoch 3/10\n",
      "330/330 [==============================] - 31s 94ms/sample - loss: 0.3917 - acc: 0.8121 - val_loss: 0.3122 - val_acc: 0.8732\n",
      "Epoch 4/10\n",
      "330/330 [==============================] - 32s 96ms/sample - loss: 0.2088 - acc: 0.9242 - val_loss: 0.2448 - val_acc: 0.8944\n",
      "Epoch 5/10\n",
      "330/330 [==============================] - 31s 93ms/sample - loss: 0.1559 - acc: 0.9576 - val_loss: 0.2661 - val_acc: 0.8873\n",
      "Epoch 6/10\n",
      "330/330 [==============================] - 32s 98ms/sample - loss: 0.1031 - acc: 0.9758 - val_loss: 0.2645 - val_acc: 0.8944\n",
      "Epoch 7/10\n",
      "330/330 [==============================] - 33s 100ms/sample - loss: 0.0516 - acc: 0.9879 - val_loss: 0.4432 - val_acc: 0.8732\n",
      "Epoch 8/10\n",
      "330/330 [==============================] - 35s 107ms/sample - loss: 0.0607 - acc: 0.9818 - val_loss: 0.2989 - val_acc: 0.8592\n",
      "Epoch 9/10\n",
      "330/330 [==============================] - 33s 101ms/sample - loss: 0.0263 - acc: 0.9970 - val_loss: 0.3507 - val_acc: 0.8732\n",
      "Epoch 10/10\n",
      "144/330 [============>.................] - ETA: 17s - loss: 0.0065 - acc: 1.0000"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import pickle\n",
    "\n",
    "pickle_in = open(\"Features_output.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"Labels_output.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "\n",
    "X = X/255.0\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), input_shape=X.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "\n",
    "model.add(Dense(64))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y, batch_size=24, epochs=10, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets use our model with some new examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 128 \n",
    "def prepare(filepath):\n",
    "    im = np.array(Image.open(filepath))\n",
    "    print(im.shape)\n",
    "    opencvImage = cv2.cvtColor(np.array(im), cv2.COLOR_RGB2BGR)    \n",
    "    new_array = cv2.resize(opencvImage, (IMG_SIZE, IMG_SIZE))\n",
    "    \n",
    "    fig, ax = plt.subplots(2, 1, constrained_layout=True)\n",
    "\n",
    "    # Set title\n",
    "    ax[0].set_title('Input Image')\n",
    "    ax[1].set_title('Output Image')\n",
    "\n",
    "    # Display the images\n",
    "    ax[1].imshow(new_array)\n",
    "\n",
    "    plt.show()\n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "\n",
    "prediction = model.predict([prepare('/home/alejandro/placas/prueba1.jpg')])\n",
    "prediction2 = model.predict([prepare('/home/alejandro/placas/prueba2.jpg')])\n",
    "prediction3 = model.predict([prepare('/home/alejandro/placas/prueba3.jpg')])\n",
    "prediction4 = model.predict([prepare('/home/alejandro/placas/prueba4.jpg')])\n",
    "prediction5 = model.predict([prepare('/home/alejandro/placas/prueba5.jpg')])\n",
    "prediction6 = model.predict([prepare('/home/alejandro/placas/prueba6.jpg')])\n",
    "prediction7 = model.predict([prepare('/home/alejandro/placas/prueba7.jpg')])\n",
    "prediction8 = model.predict([prepare('/home/alejandro/placas/prueba8.jpg')])\n",
    "prediction9 = model.predict([prepare('/home/alejandro/placas/prueba9.jpg')])\n",
    "\n",
    "\n",
    "print(prediction)\n",
    "print(prediction2)\n",
    "print(prediction3)\n",
    "print(prediction4)\n",
    "print(prediction5)\n",
    "print(prediction6)\n",
    "print(prediction7)\n",
    "print(prediction8)\n",
    "print(prediction9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems our model has trouble if it captures half plates, all the other test seemed to provide good results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
